---
output: github_document
---

# Purpose

Purpose of this work folder.

Ideally store a minimum working example data set in data folder.

Add binary files in bin, and closed R functions in code. Human Readable settings files (e.g. csv) should be placed in settings/


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(RColorBrewer)
library(xtable)
library(lubridate)
library(huxtable)
library(knitr)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
covid_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/owid-covid-data.csv")
deaths_by_cause <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/Deaths_by_cause.csv")
description <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/covid_data_description.csv")

```
\newpage
# Question 1: COVID
1.1 It might be interesting to look at vaccinations in Africa and the outbreak of the pandemic compared to other regions. For this question I could maybe also look at the deaths by cause database to see how COVID deaths differed to deaths before COVID.
```{r bar deaths}

covid_cleaned <- covid_data %>%
  filter(location %in% c("Africa", "Asia", "North America", "Oceania", "South America", "Europe")) %>% mutate(total_deaths = ifelse(is.na(total_deaths), 0, total_deaths))

covid_cleaned <- covid_cleaned %>% mutate(total_cases = ifelse(is.na(total_cases), 0, total_cases))

bar_deaths <- plot_deaths(covid_cleaned)
bar_deaths
```
This first graph shows the total number of deaths for each continent from COVID.

```{r}
library(lubridate)
library(dplyr)

suppressWarnings(line_cases <- plot_cases(covid_cleaned))
line_cases
```
This graph shows how each continent experienced a growth in total cases (in millions) in 2020.

```{r}
factors <- covid_data %>% select(location, aged_70_older, extreme_poverty, diabetes_prevalence, total_deaths_per_million) %>% group_by(location) %>% filter(!is.na(extreme_poverty)) %>% filter(!is.na(aged_70_older)) %>% filter(!is.na(diabetes_prevalence)) %>% slice(n()) %>% arrange(desc(extreme_poverty))

countries_group1 <- c("Italy", "Portugal", "Latvia", "Greece", "Spain")
countries_group2 <- c("Sierra Leone", "Gambia", "Burkina Faso", "Uganda", "Niger", "Gambia")

filtered_df <- factors %>%
  filter(location %in% c(countries_group1, countries_group2)) %>%
  mutate(group = ifelse(location %in% countries_group1, "Group 1", "Group 2"))

ggplot(data = filtered_df, aes(x = group, y = total_deaths_per_million, fill = location)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Total Deaths Comparison",
       x = "Group",
       y = "Total Deaths") +
  theme_bw()

age_plot <- grouped_age(covid_data)
age_plot
```
```{r}
poverty_plot <- grouped_poverty(covid_data)
poverty_plot
```
```{r}
factors <- covid_data %>% select(location, aged_70_older, extreme_poverty, diabetes_prevalence, total_deaths_per_million) %>% group_by(location) %>% filter(!is.na(extreme_poverty)) %>% filter(!is.na(aged_70_older)) %>% filter(!is.na(diabetes_prevalence)) %>% slice(n()) %>% arrange(desc(diabetes_prevalence))

diabetes_plot <- grouped_diabetes(covid_data)
diabetes_plot
```




```{r}
covid_cleaned <- covid_cleaned %>% mutate(weekly_hosp_admissions = ifelse(is.na(weekly_hosp_admissions), 0, weekly_hosp_admissions)) %>% mutate(weekly_icu_admissions = ifelse(is.na(weekly_icu_admissions), 0, weekly_icu_admissions))

df <- covid_cleaned %>%
        mutate(date = as.Date(date)) %>%
        filter(year(date) == 2020) %>%
        mutate(month = month(date, label = TRUE))

monthly_admissions <- df %>%
        group_by(month) %>% 
        summarize(weekly_hosp_admissions = sum(weekly_hosp_admissions))

g <- monthly_admissions %>% ggplot() +
        geom_line(aes(x = month, y = weekly_hosp_admissions)) +
        labs(title = "Total Cases per Month and Location (2020)", x = "Month", y = "Total Deaths") +
        scale_color_discrete(name = "Location")
    g
```
\newpage
```{r loading data}
london_weather <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 2/data/London/london_weather.csv")
UK_detailed <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 2/data/London/UKMonthly_Detailed.csv")
london_weather$date <-as.character(london_weather$date)


UK_detailed$DATE <- as.Date(paste0(UK_detailed$DATE, "-01"), format = "%Y-%m-%d")

london_2000 <- london_weather %>% filter(date > 19991231)
#this only includes London weather info from 2000
```

I want to compare cloud cover and sunshine in London to see what they look like compared to each other.
```{r}
graph_cloud <- avg_london(london_2000)
graph_cloud
```
I'm using the next graph to show the rainfall for every day of the month of December in 2020.
```{r london rain}
rain_graph <- london_rain(london_weather)
rain_graph
```

There's a lot of data starting all the way from 1881 which I don't think is very necessary. The weather and climate has also changed a lot since then.
```{r}
UK_1980 <- UK_detailed %>% filter (DATE >= "1980-01-01")
temp_graph <- temp_bar(UK_1980)
temp_graph
```
Question 3
```{r load data}
coldplay_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/Coldplay.csv")
metallica_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/metallica.csv")
spotify_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/Broader_Spotify_Info.csv")
```

I'm going to do a scatter plot to see the correlation between energy and popularity and then, for each album of the bands, do a bar graph of their popularity and danceability.
```{r}
correlation_cp <- cor(coldplay_data[, c("popularity", "danceability", "energy", "instrumentalness", "liveness", "loudness")])
correlation_cp
correlation_m <- cor(metallica_data[, c("popularity", "danceability", "energy", "instrumentalness", "liveness", "loudness")])
correlation_m
#correlations show that danceability had the highest positive relationship with popularity for Coldplay and the second highest for Metallica so I'm using that metric


scatter_cp <- scatter_coldplay(coldplay_data)
scatter_cp
```
```{r}
scatter_m <- scatter_metallica(metallica_data)
scatter_m
```

```{r}
top_10_danceability_songs <- spotify_data %>% select(c(name, artist, danceability)) %>% 
  arrange(desc(danceability)) %>%
  head(10)
top_10_table <- as_huxtable(top_10_danceability_songs)
top_10_table
```
```{r}
studio_coldplay <- coldplay_data %>% filter(!grepl("live|Live", name)) %>% filter(!grepl("live|Live", album_name))
studio_metallica <- metallica_data %>% filter(!grepl("live|Live", name)) %>% filter(!grepl("live|Live", album))
```

```{r}
pop_g_cp <- popularity_coldplay(studio_coldplay)
pop_g_cp
```
```{r}
pop_g_m <- popularity_metallica(studio_metallica)
pop_g_m
```
```{r}
box_cp <- box_coldplay(studio_coldplay)
box_cp
```
```{r}
box_m <- box_metallica(studio_metallica)
box_m
```
I can maybe consider doing something linked to valence to show happy vs sad. Isn't really linked to popularity though so I'm not sure yet. 











