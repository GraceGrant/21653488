---
output: github_document
---

# Purpose

Purpose of this work folder.

Ideally store a minimum working example data set in data folder.

Add binary files in bin, and closed R functions in code. Human Readable settings files (e.g. csv) should be placed in settings/


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(RColorBrewer)
library(xtable)
library(lubridate)
library(huxtable)
library(knitr)
library(kableExtra)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
covid_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/owid-covid-data.csv")
deaths_by_cause <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/Deaths_by_cause.csv")
description <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 1/data/Covid/covid_data_description.csv")

```
\newpage
# Question 1: COVID
1.1 It might be interesting to look at vaccinations in Africa and the outbreak of the pandemic compared to other regions. For this question I could maybe also look at the deaths by cause database to see how COVID deaths differed to deaths before COVID.
```{r bar deaths}

covid_cleaned <- covid_data %>%
  filter(location %in% c("Africa", "Asia", "North America", "Oceania", "South America", "Europe")) %>% mutate(total_deaths = ifelse(is.na(total_deaths), 0, total_deaths))

covid_cleaned <- covid_cleaned %>% mutate(total_cases = ifelse(is.na(total_cases), 0, total_cases))

bar_deaths <- plot_deaths(covid_cleaned)
bar_deaths
```
This first graph shows the total number of deaths for each continent from COVID.

```{r}
library(lubridate)
library(dplyr)

suppressWarnings(line_cases <- plot_cases(covid_cleaned))
line_cases
```
This graph shows how each continent experienced a growth in total cases (in millions) in 2020.

```{r}
age_plot <- grouped_age(covid_data)
age_plot
```
```{r}
poverty_plot <- grouped_poverty(covid_data)
poverty_plot
```
```{r}
factors <- covid_data %>% select(location, aged_70_older, extreme_poverty, diabetes_prevalence, total_deaths_per_million) %>% group_by(location) %>% filter(!is.na(extreme_poverty)) %>% filter(!is.na(aged_70_older)) %>% filter(!is.na(diabetes_prevalence)) %>% slice(n()) %>% arrange(desc(diabetes_prevalence))

diabetes_plot <- grouped_diabetes(covid_data)
diabetes_plot
```

```{r}
admissions_plot <- admissions(covid_data)
admissions_plot
```
\newpage
Question 2
```{r loading data}
london_weather <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 2/data/London/london_weather.csv")
UK_detailed <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 2/data/London/UKMonthly_Detailed.csv")
london_weather$date <-as.character(london_weather$date)


UK_detailed$DATE <- as.Date(paste0(UK_detailed$DATE, "-01"), format = "%Y-%m-%d")

london_2000 <- london_weather %>% filter(date > 19991231)
#this only includes London weather info from 2000
```

I want to see the sunshine and rainfall in London in December 2020.
```{r}
sun_plot <- lollipop_sun(london_2000)
sun_plot

```
I'm using the next graph to show the rainfall for every day of the month of December in 2020.
```{r london rain}
rain_graph <- london_rain(london_weather)
rain_graph



```

There's a lot of data starting all the way from 1881 which I don't think is very necessary. The weather and climate has also changed a lot since then.
```{r}
UK_1980 <- UK_detailed %>% filter (DATE >= "1980-01-01")
temp_graph <- temp_bar(UK_1980)
temp_graph
```
Question 3
```{r load data}
coldplay_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/Coldplay.csv")
metallica_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/metallica.csv")
spotify_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 3/data/Coldplay_vs_Metallica/Broader_Spotify_Info.csv")
```

I'm going to do a scatter plot to see the correlation between energy and popularity and then, for each album of the bands, do a bar graph of their popularity and danceability.
```{r}
correlation_cp <- cor(coldplay_data[, c("popularity", "danceability", "energy", "instrumentalness", "liveness", "loudness")])
correlation_cp
correlation_m <- cor(metallica_data[, c("popularity", "danceability", "energy", "instrumentalness", "liveness", "loudness")])
correlation_m
#correlations show that danceability had the highest positive relationship with popularity for Coldplay and the second highest for Metallica so I'm using that metric


scatter_cp <- scatter_coldplay(coldplay_data)
scatter_cp
```
```{r}
scatter_m <- scatter_metallica(metallica_data)
scatter_m
```

```{r}
top_10_danceability_songs <- spotify_data %>% select(c(name, artist, danceability)) %>% 
  arrange(desc(danceability)) %>%
  head(10)
top_10_table <- as_huxtable(top_10_danceability_songs)
top_10_table
```
```{r}
studio_coldplay <- coldplay_data %>% filter(!grepl("live|Live", name)) %>% filter(!grepl("live|Live", album_name))
studio_metallica <- metallica_data %>% filter(!grepl("live|Live", name)) %>% filter(!grepl("live|Live", album))
```

```{r}
pop_g_cp <- popularity_coldplay(studio_coldplay)
pop_g_cp
```
```{r}
pop_g_m <- popularity_metallica(studio_metallica)
pop_g_m
```
```{r}
box_cp <- box_coldplay(studio_coldplay)
box_cp
```
```{r}
box_m <- box_metallica(studio_metallica)
box_m
```
I can maybe consider doing something linked to valence to show happy vs sad. Isn't really linked to popularity though so I'm not sure yet. 

\newpage
Question 4
```{r load data}
titles_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 4/data/netflix/titles.csv")
credits_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 4/data/netflix/credits.csv")
merged_data <- merge(titles_data, credits_data, by = "id")
```

This creates a table of the top 20 movies and shows based on director.
```{r}
directors <- merged_data %>% filter(role == "DIRECTOR") %>% filter(release_year > 1980) %>% select (c("title", "type", "imdb_score", "name")) %>% arrange(desc(imdb_score)) %>% slice(1:20)
directors_table <- as_hux(directors)
set_all_borders(directors_table, 1)

directors_table

directors <- merged_data %>% filter(role == "DIRECTOR") %>% filter(release_year > 1980) %>% select (c("title", "type", "imdb_score", "name")) %>% arrange(desc(imdb_score)) %>% slice(1:20)
directors_table <- as_hux(directors)
set_all_borders(directors_table, 1)

directors_table <- kable(directors, row.names=TRUE, 
                         caption = "Top Directors and Titles Based on IMDB Score",
                         booktabs = TRUE) %>% 
    kable_styling(full_width = TRUE, 
                  latex_options = c("striped", "scale_down", "HOLD_position"), 
                  font_size = 13)
directors_table


directors_table <- kable(directors, row.names=TRUE,
                         caption = "Top Directors and Titles Based on IMDB Score",
                         booktabs = TRUE) %>% 
    kable_styling(full_width = TRUE, 
                  latex_options = c("striped", "scale_down", "HOLD_position"), 
                  font_size = 13)
directors_table
```
I'm using the next graph to see, firstly, what the top 10 highest rated movies and TV shows are and then what their genres are.
```{r}
shows <- titles_data %>% filter(type == "SHOW") %>% arrange(desc(imdb_score)) %>% filter(title != '#ABtalks') %>% slice(1:10)
movies <- titles_data %>% filter(type == "MOVIE") %>% arrange(desc(imdb_score)) %>% slice(1:10)

genre_tv <- genre_bar_tv(titles_data)
genre_tv
```
```{r}
genre_movies <- genre_bar_movies(titles_data)
genre_movies
```
I want to see how the maximum IMDB score per year has changed over time.
```{r}
score_plot <- line_score(merged_data)
score_plot

```
Question 5
```{r load data}
googleplay_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 5/data/googleplay/googleplaystore.csv")
reviews_data <- read.csv("/Users/gracegrant/Documents/Postgrad/Masters/Data Science/Take home exam/Question 5/data/googleplay/googleplaystore_user_reviews.csv")
merged_google <- merge(googleplay_data, reviews_data, by = "App")
```
I want to make a bubble chart of the different ratings of apps linked to their size and then how many downloads they have which I'm assuming links to profitability. I can also colour code by reviewer sentiment to add more to the graph.

```{r}
bubble_chart <- bubble(merged_google)
bubble_chart
```
I want to see some of the characteristics of the different categories to determine which type of app would be the best to develop.
```{r}
categories <- filter_merged  %>% select(c("App", "Category", "Rating", "Installs")) %>% unique() %>% arrange(desc(Rating)) %>% slice(1:20)

categories_table <- kable(categories, row.names=TRUE, 
                         caption = "Top 20 Rated Apps",
                         booktabs = TRUE) %>% 
    kable_styling(full_width = TRUE, 
                  latex_options = c("striped", "scale_down", "HOLD_position"), 
                  font_size = 13)
categories_table
```























